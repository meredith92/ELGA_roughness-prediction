{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ELGA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data pre processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor\n",
    "from sklearn.svm import SVR, LinearSVR\n",
    "from sklearn.linear_model import ElasticNet, SGDRegressor, BayesianRidge\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data1.csv')\n",
    "y = data['Roughness']\n",
    "X = data.drop('Roughness', axis = 1)\n",
    "X_train, X_test, y_train, y_test =train_test_split(X,y,test_size=0.1,random_state=100)\n",
    "poly = PolynomialFeatures(2,include_bias=True)\n",
    "Xtrans=poly.fit_transform(X_train)\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit(Xtrans).transform(Xtrans)\n",
    "scalery =MinMaxScaler()\n",
    "y_scaled=scalery.fit(np.array(y_train).reshape(-1, 1)).transform(np.array(y_train).reshape(-1, 1)).ravel()\n",
    "Xtrans_test=poly.transform(X_test)\n",
    "X_scaled_test = scaler.transform(Xtrans_test)\n",
    "y_scaled_test=scalery.transform(np.array(y_test).reshape(-1, 1)).ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hyperparameter cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class grid():\n",
    "    def __init__(self,model):\n",
    "        self.model = model\n",
    "    \n",
    "    def grid_get(self,X,y,param_grid):\n",
    "        grid_search = GridSearchCV(self.model,param_grid,cv=5, scoring=\"neg_mean_absolute_error\")\n",
    "        grid_search.fit(X,y)\n",
    "        print(grid_search.best_params_, -grid_search.best_score_)\n",
    "        grid_search.cv_results_['mean_test_score'] = -grid_search.cv_results_['mean_test_score']\n",
    "        print(pd.DataFrame(grid_search.cv_results_)[['params','mean_test_score','std_test_score']])\n",
    "\n",
    "grid(Ridge()).grid_get(X_scaled, y_scaled,{\"alpha\":[0.8,0.7,0.9,1,1.5]})\n",
    "grid(Lasso()).grid_get(X_scaled, y_scaled,{\"alpha\":[0.01,0.02,0.03],\"max_iter\":[100,200,300]})\n",
    "grid(RandomForestRegressor()).grid_get(X_scaled, y_scaled,{\"random_state\":[140,150,160],\"min_samples_split\":[2,3,4,5,6,7,8],\"n_estimators\":[7,6,5]})\n",
    "grid(ElasticNet()).grid_get(X_scaled, y_scaled,{\"alpha\":[0.001],\"max_iter\":[100]})\n",
    "grid(XGBRegressor(objective='reg:squarederror')).grid_get(X_scaled, y_scaled,{\"max_depth\":[4],\"learning_rate\":[0.04],\"n_estimators\":[1300,1600,1500,1400,1700]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Multi Machine learning regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rd=Ridge(alpha=0.9)\n",
    "las=Lasso(alpha=0.01,max_iter=10000,tol=0.001)\n",
    "rf=RandomForestRegressor(random_state=150,min_samples_split=5,n_estimators=6)\n",
    "ela=ElasticNet(tol=0.01,alpha=0.01,max_iter=100)\n",
    "xgb=XGBRegressor(objective='reg:squarederror')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse_cv(model,X,y):\n",
    "    rmse = -cross_val_score(model, X, y, scoring=\"neg_mean_absolute_error\", cv=5)\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [rd,las,rf,ela,xgb]\n",
    "names = [\"rd\", \"las\", \"rf\", \"ela\", \"xgb\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, model in zip(names, models):\n",
    "    score = rmse_cv(model, X_scaled, y_scaled)\n",
    "    print(\"{}: {:.6f}, {:.4f}\".format(name,score.mean(),score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, model in zip(names, models):\n",
    "    model.fit(X_scaled,y_scaled)\n",
    "    pred=model.predict(X_scaled_test)\n",
    "    ypred=scalery.inverse_transform(pred.reshape(-1, 1)).ravel()\n",
    "    print(ypred) ## used in GA\n",
    "    mean=np.mean(np.abs((y_test-ypred)/ypred))\n",
    "    print(name,mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. GA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import geatpy as ea\n",
    "from aimfunc import aimfunc\n",
    "import time\n",
    "\n",
    "x1=[0,1]\n",
    "x2=[0,1]\n",
    "x3=[0,1]\n",
    "x4=[0,1]\n",
    "x5=[0,1]\n",
    "\n",
    "b1=[1,1]\n",
    "b2=[1,1]\n",
    "b3=[1,1]\n",
    "b4=[1,1]\n",
    "b5=[1,1]\n",
    "\n",
    "ranges=np.vstack([x1,x2,x3,x4,x5]).T\n",
    "borders=np.vstack([b1,b2,b3,b4,b5]).T\n",
    "varTypes=np.array([0,0,0,0,0])\n",
    "Encoding='BG'\n",
    "codes=[0,0,0,0,0]\n",
    "precisions=[2,2,2,2,2]\n",
    "scales=[0,0,0,0,0]\n",
    "FieldD=ea.crtfld(Encoding,varTypes,ranges,borders,precisions,codes,scales)\n",
    "NIND      = 10000;\n",
    "MAXGEN    = 100;\n",
    "maxormins = [1] \n",
    "maxormins = np.array(maxormins)\n",
    "selectStyle = 'rws' \n",
    "recStyle  = 'xovdp' \n",
    "mutStyle ='mutbin'\n",
    "\n",
    "pc=0.9\n",
    "Lind=int(np.sum(FieldD[0,:]))\n",
    "pm=1/Lind\n",
    "obj_trace=np.zeros((MAXGEN,2))\n",
    "var_trace=np.zeros((MAXGEN,Lind))\n",
    "start_time=time.time()\n",
    "Chrom=ea.crtpc(Encoding,NIND,FieldD)\n",
    "variable=ea.bs2real(Chrom,FieldD)\n",
    "\n",
    "ObjV,CV=aimfunc(variable)\n",
    "FitnV = ea.ranking(ObjV,CV,maxormins)\n",
    "best_ind = np.argmax(FitnV)\n",
    "#\n",
    "for gen in range(MAXGEN):\n",
    "    SelCh = Chrom[ea.selecting(selectStyle,FitnV,NIND-1),:] \n",
    "    SelCh = ea.recombin(recStyle, SelCh, pc) \n",
    "    SelCh = ea.mutate(mutStyle, Encoding, SelCh, pm)\n",
    "    Chrom = np.vstack([Chrom[best_ind, :], SelCh])\n",
    "    Phen = ea.bs2real(Chrom, FieldD)\n",
    "    ObjV, CV = aimfunc(Phen)\n",
    "    FitnV = ea.ranking(ObjV, CV,maxormins)\n",
    "    best_ind = np.argmax(FitnV) \n",
    "    obj_trace[gen,0]=np.sum(ObjV)/ObjV.shape[0] \n",
    "    obj_trace[gen,1]=ObjV[best_ind]\n",
    "    var_trace[gen,:]=Chrom[best_ind,:]\n",
    "\n",
    "end_time = time.time()\n",
    "ea.trcplot(obj_trace, [['individuals mean objective value ', 'best individual objective value']])\n",
    "\"\"\"============================result============================\"\"\"\n",
    "best_gen = np.argmax(obj_trace[:, [1]])\n",
    "print('optimal solution objective value：', obj_trace[best_gen, 1])\n",
    "variable =ea.bs2real(var_trace[[best_gen], :], FieldD)\n",
    "# variable = var_trace[[best_gen], :] \n",
    "print('optimal parameter value：')\n",
    "for i in range(variable.shape[1]):\n",
    "    print('x'+str(i)+'=',variable[0, i])\n",
    "print('time：', end_time - start_time, 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def aimfunc(Phen):\n",
    "    x1 = Phen[:, [0]] \n",
    "    x2 = Phen[:, [1]]\n",
    "    x3 = Phen[:, [2]]\n",
    "    x4 = Phen[:, [3]]\n",
    "    x5 = Phen[:, [4]]\n",
    "    # pred is the predictive value predicted by each model \n",
    "    pred = np.array([[74,166,107,70,60],\n",
    "                     [73,125,97,69,66],\n",
    "                     [68,120,70,71,76],\n",
    "                     [79,120,105,68,64],\n",
    "                     [98,140,89,43,45]])\n",
    "    test = np.array([44,144,88,66,47])\n",
    "    predy=pred[0] * x1 + pred[1] * x2 + pred[2] * x3 + pred[3] * x4 + pred[4] * x5\n",
    "    ObjV = np.mean(np.abs(predy - test) / predy,axis=1,keepdims=True)\n",
    "    CV = np.abs(x1 + x2 + x3 + x4 + x5 - 1)\n",
    "    return [ObjV,CV]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageWeight(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self,mod,weight):\n",
    "        self.mod = mod\n",
    "        self.weight = weight\n",
    "        \n",
    "    def fit(self,X,y):\n",
    "        self.models_ = [clone(x) for x in self.mod]\n",
    "        for model in self.models_:\n",
    "            model.fit(X,y)\n",
    "        return self\n",
    "    \n",
    "    def predict(self,X):\n",
    "        w = list()\n",
    "        pred = np.array([model.predict(X) for model in self.models_])\n",
    "        print(scalery.inverse_transform(np.array(pred).reshape(-1, 1)).ravel())\n",
    "        \n",
    "        # for every data point, single model prediction times weight, then add them together\n",
    "        for data in range(pred.shape[1]):\n",
    "            single = [pred[model,data]*weight for model,weight in zip(range(pred.shape[0]),self.weight)]\n",
    "            w.append(np.sum(single))\n",
    "        return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ELGA \n",
    "#weight comes from the result of GA\n",
    "weight_avg = AverageWeight(mod = models,weight=weight)\n",
    "weight_avg.fit(X_scaled,y_scaled)\n",
    "pre=weight_avg.predict(X_scaled_test)\n",
    "Avgpred=scalery.inverse_transform(np.array(pre).reshape(-1, 1)).ravel()\n",
    "np.mean(np.abs((y_test-Avgpred)/y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy  as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import model_selection\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers,initializers,optimizers,losses\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('data1.csv')\n",
    "y=df['Roughness']\n",
    "X=df.drop('Roughness',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M1 = MinMaxScaler()\n",
    "X_scaled = M1.fit_transform(X)\n",
    "M2 = MinMaxScaler()\n",
    "y_scaled = M2.fit_transform(np.array(y).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_valid,y_train,y_valid=model_selection.train_test_split(X_scaled,y_scaled,test_size=0.1,random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_pred(y_true, y_pred):\n",
    "    return K.mean(tf.abs(y_pred-y_true)/y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Built\n",
    "inputs=keras.Input(shape=(6,))\n",
    "x=layers.Dense(4,activation='tanh')(inputs)\n",
    "x=layers.Dense(4,activation='tanh')(x)\n",
    "x=layers.Dense(4,activation='tanh')(x)\n",
    "x=layers.Dense(4,activation='tanh')(x)\n",
    "outputs=layers.Dense(1,activation='linear')(x)\n",
    "\n",
    "model=keras.Model(inputs=inputs,outputs=outputs)\n",
    "model.compile(loss='mean_absolute_error',optimizer='adam',metrics=[mean_pred])\n",
    "\n",
    "history=model.fit(X_train,y_train,batch_size=1,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction\n",
    "pred=model.predict(X_valid)\n",
    "ypred=M2.inverse_transform(pred.reshape(-1, 1)).ravel()\n",
    "yvalid=M2.inverse_transform(y_valid.reshape(-1, 1)).ravel()\n",
    "np.mean(np.abs(yvalid-ypred)/ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the loss and mean_pred\n",
    "loss = history.history.get('loss')\n",
    "mean_pred = history.history.get('mean_pred')\n",
    "val_loss = history.history.get('val_loss')\n",
    "val_mean_pred = history.history.get('val_mean_pred')\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(loss)\n",
    "plt.plot(val_loss)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend(['loss','val_loss'])\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(mean_pred)\n",
    "plt.plot(val_mean_pred)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"mean_pred\")\n",
    "plt.legend(['mean_pred','val_mean_pred'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
